name: Daily WFH Job Scrape

on:
  schedule:
    - cron: '0 13 * * *'
  workflow_dispatch:

permissions:
  contents: write

jobs:
  build:
    runs-on: ubuntu-latest
    steps:
      - name: Checkout code
        uses: actions/checkout@v4

      - name: Set up Python
        uses: actions/setup-python@v4
        with:
          python-version: '3.9'

      - name: Install dependencies
        run: |
          pip install requests beautifulsoup4 playwright
          playwright install chromium

      - name: Run Proxy Tester and Scraper
        run: |
          python fast_us_proxies.py
          python wfh_high_pay_scraper.py

      - name: Send Results to Discord
        if: always()
        env:
          DISCORD_WEBHOOK: ${{ secrets.DISCORD_WEBHOOK }}
        run: |
          # 1. Send the Job Leads CSV
          if [ -f "wfh_leads.csv" ]; then
            curl -F "file=@wfh_leads.csv" \
                 -F "content=ðŸš€ **Daily High-Pay Report ($10-$50/hr)**" \
                 $DISCORD_WEBHOOK
          fi

          # 2. Send all 5 screenshots
          for file in *.png; do
            if [ -f "$file" ]; then
              curl -F "file=@$file" \
                   -F "content=ðŸ“¸ **Site Update:** ${file%.*}" \
                   $DISCORD_WEBHOOK
            fi
          done

      - name: Commit and Push changes
        if: always()
        uses: stefanzweifel/git-auto-commit-action@v5
        with:
          commit_message: "Updated Job Boards, CSV, and Screenshots"
          file_pattern: 'fast_us_proxies.txt wfh_leads.csv *.png'