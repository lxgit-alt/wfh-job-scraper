name: Daily WFH Job Scrape

on:
  schedule:
    - cron: '0 13 * * *'
  workflow_dispatch:

permissions:
  contents: write

jobs:
  scrape:
    runs-on: ubuntu-latest
    steps:
      - name: Checkout Repository
        uses: actions/checkout@v4

      - name: Setup Python
        uses: actions/setup-python@v5
        with:
          python-version: '3.10'

      - name: Install Dependencies
        run: |
          pip install playwright requests
          playwright install firefox

      - name: Run Scraper
        env:
          # Your Premium Proxy Credentials
          PROXY_USER: "muchzrvn"
          PROXY_PASS: "iypbhjpq6psl"
        run: python wfh_high_pay_scraper.py

      - name: Upload to Discord
        if: always()
        env:
          DISCORD_WEBHOOK: ${{ secrets.DISCORD_WEBHOOK }}
        run: |
          if [ -f "wfh_leads.csv" ]; then
            curl -F "file=@wfh_leads.csv" -F "content=ðŸ“ˆ **New High-Pay WFH Jobs Found**" $DISCORD_WEBHOOK
          fi
          for img in *.png; do
            if [ -f "$img" ]; then
              curl -F "file=@$img" -F "content=ðŸ“¸ Site Preview: ${img%_jobs.png}" $DISCORD_WEBHOOK
            fi
          done

      - name: Git Commit and Push
        if: always()
        uses: stefanzweifel/git-auto-commit-action@v5
        with:
          commit_message: "Scrape Update: $(date +'%Y-%m-%d')"
          file_pattern: 'wfh_leads.csv *.png'